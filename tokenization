Breaks down a long text string into smaller units called tokens, which can represent words, symbols, or numbers. This is a basic step in processing text for NLP applications.
